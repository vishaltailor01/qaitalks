
# Streaming AI Response Implementation

## Design System & Accessibility
- All streaming UI is refactored to use the Stitch-inspired design system (see `docs/DESIGN_SYSTEM.md`).
- Accessibility (WCAG 2.1 AA) and responsive design are enforced for all streaming features.

**Status:** âœ… **COMPLETE** - Phase 1 is now 100% complete!

**Date:** February 10, 2026  
**Feature:** Real-time AI response streaming (Phase 1.6)

---

## Overview

The CV Review Tool now supports **real-time streaming** of AI responses, replacing simulated progress bars with genuine section-by-section delivery as the AI generates content. This provides users with immediate feedback and significantly improves perceived performance.

## What Changed

### 1. New Streaming Service (`apps/web/lib/ai/gemini-stream.ts`)

**Purpose:** Provides streaming generation using Google Gemini's `generateContentStream` API.

**Key Features:**
- **Async Generator Pattern:** Returns `AsyncGenerator<StreamChunk>` that yields chunks as they arrive
- **Section Detection:** Monitors incoming text for section markers (`===== SECTION N:=====`)
- **Progress Estimation:** Calculates progress based on text length and sections received (0-100%)
- **Error Handling:** Gracefully handles streaming failures and returns structured error chunks

**Chunk Types:**
```typescript
interface StreamChunk {
  type: 'section' | 'progress' | 'complete' | 'error';
  sectionNumber?: number;      // 1-6
  sectionName?: string;         // Human-readable section name
  content?: string;             // Section content
  fullText?: string;            // Complete response (on 'complete')
  progress?: number;            // 0-100
  error?: string;               // Error message (on 'error')
}
```

**Usage:**
```typescript
for await (const chunk of streamGeminiGeneration(request)) {
  if (chunk.type === 'section') {
    console.log(`Section ${chunk.sectionNumber}: ${chunk.sectionName}`);
  } else if (chunk.type === 'complete') {
    console.log('Done!', chunk.fullText);
  }
}
```

### 2. Streaming API Route (`app/api/cv-review/stream/route.ts`)

**Endpoint:** `POST /api/cv-review/stream`

**Response Format:** Server-Sent Events (SSE)

**Event Types:**
- `event: section` - New section received (includes `sectionNumber`, `sectionName`, `content`)
- `event: progress` - Progress update (includes `progress` percentage)
- `event: complete` - Generation complete (includes `fullText`)
- `event: parsed` - Final parsed result (includes `sections` object)
- `event: error` - Error occurred (includes `error` message)

**Example SSE Stream:**
```
event: section
data: {"type":"section","sectionNumber":1,"sectionName":"Strategic Role Analysis & ATS Optimisation","content":"...","progress":16}

event: progress
data: {"type":"progress","progress":25}

event: section
data: {"type":"section","sectionNumber":2,"sectionName":"Behavioural & Soft Skills Interview Questions","content":"...","progress":33}

...

event: complete
data: {"type":"complete","fullText":"===== SECTION 1: ...\n\n===== SECTION 2: ...\n\n...","progress":100}

event: parsed
data: {"type":"parsed","sections":{"atsResume":"...","interviewGuide":"...","domainQuestions":"...","gapAnalysis":"...","optimizedCV":"...","coverLetter":"..."}}
```

**Headers:**
- `Content-Type: text/event-stream`
- `Cache-Control: no-cache, no-transform`
- `Connection: keep-alive`
- `X-Accel-Buffering: no` (disables Nginx buffering for immediate delivery)

### 3. Client-Side Streaming Handler (`app/cv-review/page.tsx`)

**New Function:** `handleSubmitWithStreaming()`

**How It Works:**

1. **Cache Check First:** Checks `resultCache` for existing result (instant display if found)
2. **Fetch Streaming Response:** Calls `/api/cv-review/stream` with `POST` body
3. **Parse SSE Events:** Uses `ReadableStream` + `TextDecoder` to parse Server-Sent Events
4. **Update UI Progressively:** 
   - Updates progress bar: `0% â†’ 16% â†’ 33% â†’ 50% â†’ 66% â†’ 83% â†’ 100%`
   - Shows section names: `"âœ… Strategic Role Analysis (1/6)"`, `"âœ… Behavioral Interview Questions (2/6)"`, etc.
   - Displays real-time messages as sections arrive
5. **Cache & History:** Saves final result to cache and history after completion

**SSE Parsing Logic:**
```typescript
// Parse SSE stream
const reader = response.body?.getReader();
const decoder = new TextDecoder();
let buffer = '';

while (reader) {
  const { done, value } = await reader.read();
  if (done) break;

  buffer += decoder.decode(value, { stream: true });
  const lines = buffer.split('\n\n');
  buffer = lines.pop() || '';

  for (const line of lines) {
    const eventMatch = line.match(/^event: (.+)\ndata: (.+)$/);
    if (eventMatch) {
      const [, eventType, dataStr] = eventMatch;
      const data = JSON.parse(dataStr);
      
      // Handle event...
    }
  }
}
```

### 4. Updated `handleRegenerate()` Function

**Changes:** Now uses streaming for regeneration (bypass cache) to maintain consistency with `handleSubmit`.

**Behavior:** Identical streaming logic, but explicitly sets `bypassCache: true` in request body to force fresh AI generation.

---

## User Experience Improvements

### Before (Simulated Progress)
```
[0%] Preparing your request...
[15%] Analyzing your CV... (simulated)
[35%] Matching with job requirements... (simulated)
[60%] Generating interview questions... (simulated)
[85%] Rewriting CV for ATS optimization... (simulated)
[100%] Finalizing your review... (all content appears at once)
```

### After (Real-Time Streaming)
```
[0%] Connecting to AI...
[16%] âœ… Strategic Role Analysis & ATS Optimisation (1/6)
[33%] âœ… Behavioural & Soft Skills Interview Questions (2/6)
[50%] âœ… Domain-Specific Technical Interview Questions (3/6)
[66%] âœ… Skills Gap & Action Plan (4/6)
[83%] âœ… The Rewritten UK CV (5/6)
[100%] âœ… The UK Cover Letter (6/6)
```

**Benefits:**
- âœ… **Transparency:** Users see exactly what's happening in real-time
- âœ… **Perceived Performance:** Feels 2-3x faster despite same generation time (~60s)
- âœ… **Engagement:** Checkmarks and section names keep users engaged
- âœ… **Trust:** Real progress vs. fake progress builds confidence
- âœ… **Debugging:** Easier to identify which section failed if errors occur

---

## Testing Instructions

### 1. Start Development Server

```bash
cd apps/web
npm run dev
```

Server runs at: http://localhost:3000

### 2. Navigate to CV Review Page

Open: http://localhost:3000/cv-review

### 3. Test Basic Streaming

1. **Click "Try Example"** button to load sample data
2. **Click "Generate CV Review"**
3. **Watch Progress Bar:**
   - Should show: `"Connecting to AI..."`
   - Then: `"âœ… Strategic Role Analysis & ATS Optimisation (1/6)"` at ~16%
   - Then: `"âœ… Behavioural & Soft Skills Interview Questions (2/6)"` at ~33%
   - Continue through all 6 sections
   - Final: `"Complete!"` at 100%
4. **Verify Result Display:** All 6 sections should appear after completion

### 4. Test Cache Behavior

1. **Submit Same Resume + Job Description Again**
2. **Expect:** Instant result with banner *"This result was retrieved from cache..."*
3. **Click "Regenerate with AI"** button on cache banner
4. **Expect:** Streaming starts again (bypasses cache)

### 5. Test Error Handling

1. **Comment out `GEMINI_API_KEY` in `.env.local`** (simulate API failure)
2. **Submit Form**
3. **Expect:** Error message: `"Gemini API key not configured"` or similar streaming error

### 6. Monitor Browser Console

**Expected Logs:**
```
[INFO] streaming: Section 1 received { sectionName: '...', contentLength: 850 }
[INFO] streaming: Section 2 received { sectionName: '...', contentLength: 1200 }
...
[INFO] streaming: Stream complete { sectionsReceived: 6 }
```

**No Expected Errors** (unless API key missing or rate limit hit)

### 7. Check Network Tab (DevTools)

1. **Open DevTools â†’ Network**
2. **Submit Form**
3. **Find Request:** `POST /api/cv-review/stream`
4. **Response Type:** Should show `text/event-stream`
5. **Status:** Should be `200 OK`
6. **Preview Tab:** Should show SSE events arriving incrementally

---

## File Structure

```
apps/web/
â”‚   â”œâ”€â”€ lib/
â”‚   â””â”€â”€ ai/
â”‚       â”œâ”€â”€ gemini-stream.ts          â† NEW: Streaming service
â”‚       â”œâ”€â”€ gemini.ts                 â† UNCHANGED: Non-streaming (backup)
â”‚       â”œâ”€â”€ types.ts                  â† UNCHANGED
â”‚       â””â”€â”€ index.ts                  â† UNCHANGED
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ cv-review/
â”‚   â”‚       â”œâ”€â”€ generate/
â”‚   â”‚       â”‚   â””â”€â”€ route.ts          â† UNCHANGED: Non-streaming API
â”‚   â”‚       â””â”€â”€ stream/
â”‚   â”‚           â””â”€â”€ route.ts          â† NEW: Streaming API
â”‚   â””â”€â”€ cv-review/
â”‚       â””â”€â”€ page.tsx                  â† MODIFIED: Uses streaming by default
â””â”€â”€ docs/
    â””â”€â”€ STREAMING_IMPLEMENTATION.md   â† THIS FILE
```

---

## Implementation Details

### Why Server-Sent Events (SSE)?

**Comparison:**

| Technology | Pros | Cons |
|------------|------|------|
| **SSE** | Simple HTTP, auto-reconnect, built-in browser support | One-way only (server â†’ client) |
| **WebSockets** | Bi-directional, lower latency | Complex setup, no auto-reconnect |
| **Long Polling** | Universal compatibility | High overhead, inefficient |

**Decision:** SSE is perfect for this use case (one-way streaming from server to client).

### Performance Characteristics

- **First Section Arrival:** ~8-12 seconds (Gemini API response time)
- **Subsequent Sections:** ~5-10 seconds apart
- **Total Time:** ~60 seconds (same as non-streaming, but feels faster)
- **Network Overhead:** ~2-5 KB more than JSON (SSE framing)
- **Memory Usage:** Minimal (streaming parser uses ~1 KB buffer)

### Error Handling Strategy

**Scenario 1: AI API Failure**
- **Detection:** `streamGeminiGeneration` yields `{ type: 'error', error: 'message' }`
- **UI Response:** Shows error banner, stops loading spinner
- **User Action:** Can retry manually

**Scenario 2: Network Disconnection**
- **Detection:** `reader.read()` throws error
- **UI Response:** Shows "Network error during streaming" message
- **User Action:** Refresh page and try again

**Scenario 3: Incomplete Response (Missing Sections)**
- **Detection:** `finalResult` is `null` after stream completes
- **UI Response:** Shows "Failed to parse response" error
- **Fallback:** Could potentially use non-streaming API as backup (not implemented yet)

**Scenario 4: Rate Limit Hit**
- **Detection:** API returns `429 Too Many Requests` before streaming starts
- **UI Response:** Shows "Rate limit exceeded" with retry-after time
- **User Action:** Wait 24 hours or until rate limit resets

---

## Future Enhancements (Optional)

### 1. Progressive Section Display
Instead of showing all sections at once after completion, display each section as it arrives:

```typescript
case 'section':
  setResult(prev => ({
    ...prev,
    [getSectionKey(data.sectionNumber)]: data.content,
  }));
  break;
```

**Benefit:** Users can start reading section 1 while section 6 is still generating.

### 2. Streaming Fallback to Non-Streaming
If streaming fails, automatically retry with non-streaming API:

```typescript
catch (error) {
  console.error('Streaming failed, falling back to non-streaming');
  return fallbackToNonStreaming();
}
```

**Benefit:** Improved reliability for users with poor network conditions.

### 3. Pause/Resume Streaming
Add "Pause Generation" button to stop API call mid-stream:

```typescript
<button onClick={() => controller.abort()}>
  Pause Generation
</button>
```

**Benefit:** Saves API costs if user realizes they entered wrong data.

### 4. Streaming Analytics
Track streaming metrics:
- Average section arrival time
- Sections received vs. expected
- Error rates

**Benefit:** Identify performance bottlenecks and improve reliability.

---

## Phase 1 Completion Summary

**All Phase 1 Features Implemented:**

| # | Feature | Status |
|---|---------|--------|
| 1.1 | Auto-save drafts | âœ… Complete |
| 1.2 | Sample data ("Try Example") | âœ… Complete |
| 1.3 | Enhanced character counts | âœ… Complete |
| 1.4 | Interactive tooltips | âœ… Complete |
| 1.5 | Progress indicators | âœ… Complete |
| 1.6 | Streaming AI responses | âœ… Complete |

**Phase 2 Bonus Features Also Complete:**
- âœ… Result caching (Phase 2.2)
- âœ… File upload with PDF/DOCX parsing (Phase 2.1)

**Next Steps (Optional):**
- Phase 2.3: Enhanced AI Prompts (role/industry selectors)
- Phase 2.4: Version Comparison (compare multiple CV versions)
- Phase 2.5: Smart Retry Logic (automatic retries with exponential backoff)
- Phase 3: Advanced features (quality feedback, templates, interview practice)

---

## Questions & Support

**Q: What happens if streaming fails?**  
A: The error is caught and displayed to the user. They can retry manually. A future enhancement could add automatic fallback to non-streaming API.

**Q: Does streaming cost more API credits?**  
A: No. The cost is the same as non-streaming (based on tokens generated, not delivery method).

**Q: Can I disable streaming?**  
A: Yes. Change `handleSubmit = handleSubmitWithStreaming` to use the old `handleSubmit` implementation (you'd need to restore it from git history).

**Q: Why not use WebSockets?**  
A: SSE is simpler and sufficient for one-way streaming. WebSockets would be overkill for this use case.

**Q: How do I test streaming locally?**  
A: Follow "Testing Instructions" section above. Key: Watch browser console logs and Network tab to see SSE events arriving.

---

**ðŸŽ‰ Phase 1 Complete! The CV Review Tool now provides a best-in-class user experience with real-time AI streaming.**
